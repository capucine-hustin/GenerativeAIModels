{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e16de7-3986-49ee-87c7-208b2480443e",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4149827b-781a-4910-a015-9e764bb7ad2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 20:00:37.879113: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e24cc67-9ea1-403e-87a3-4a1340910555",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d57ffc57-5fbc-45c2-8850-fe9c9ad4925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "n_residual_blocks = 5\n",
    "# The data, split between train and test sets\n",
    "mnist = keras.datasets.mnist\n",
    "(x, _), (y, _) = mnist.load_data()\n",
    "# Concatenate all the images together\n",
    "data = np.concatenate((x, y), axis=0)\n",
    "# Round all pixel values less than 33% of the max 256 value to 0\n",
    "# anything above this value gets rounded up to 1 so that all values are either\n",
    "# 0 or 1\n",
    "data = np.where(data < (0.33 * 256), 0, 1)\n",
    "data = data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ceae5b-f7ca-4459-b791-c71e66464b92",
   "metadata": {},
   "source": [
    "### PixelConvLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "381df7c7-f9c8-4379-8502-f4c71431b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first layer is the PixelCNN layer. This layer simply builds on the 2D convolutional layer, but includes masking.\n",
    "class PixelConvLayer(layers.Layer):\n",
    "    def __init__(self, mask_type, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mask_type = mask_type\n",
    "        self.conv = layers.Conv2D(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Build the conv2d layer to initialize kernel variables\n",
    "        self.conv.build(input_shape)\n",
    "        # Use the initialized kernel to create the mask\n",
    "        kernel_shape = tf.shape(self.conv.kernel)\n",
    "        self.mask = np.zeros(shape=kernel_shape)\n",
    "        self.mask[: kernel_shape[0] // 2, ...] = 1.0\n",
    "        self.mask[kernel_shape[0] // 2, : kernel_shape[1] // 2, ...] = 1.0\n",
    "        if self.mask_type == \"B\":\n",
    "            self.mask[kernel_shape[0] // 2, kernel_shape[1] // 2, ...] = 1.0\n",
    "\n",
    "    def call(self, inputs):\n",
    "        self.conv.kernel.assign(self.conv.kernel * self.mask)\n",
    "        return self.conv(inputs)\n",
    "\n",
    "\n",
    "# Next, we build our residual block layer.\n",
    "# This is just a normal residual block, but based on the PixelConvLayer.\n",
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv1 = keras.layers.Conv2D(\n",
    "            filters=filters, kernel_size=1, activation=\"relu\"\n",
    "        )\n",
    "        self.pixel_conv = PixelConvLayer(\n",
    "            mask_type=\"B\",\n",
    "            filters=filters // 2,\n",
    "            kernel_size=3,\n",
    "            activation=\"relu\",\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        self.conv2 = keras.layers.Conv2D(\n",
    "            filters=filters, kernel_size=1, activation=\"relu\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pixel_conv(x)\n",
    "        x = self.conv2(x)\n",
    "        return keras.layers.add([inputs, x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cde2c6-bc93-4a00-97db-c436d4052a16",
   "metadata": {},
   "source": [
    "### PixelCNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af96fc7f-cd69-435e-974e-43947128eba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(128, 28, 28, 1)]        0         \n",
      "                                                                 \n",
      " pixel_conv_layer (PixelCon  (128, 28, 28, 128)        6400      \n",
      " vLayer)                                                         \n",
      "                                                                 \n",
      " residual_block (ResidualBl  (128, 28, 28, 128)        98624     \n",
      " ock)                                                            \n",
      "                                                                 \n",
      " residual_block_1 (Residual  (128, 28, 28, 128)        98624     \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " residual_block_2 (Residual  (128, 28, 28, 128)        98624     \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " residual_block_3 (Residual  (128, 28, 28, 128)        98624     \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " residual_block_4 (Residual  (128, 28, 28, 128)        98624     \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " pixel_conv_layer_6 (PixelC  (128, 28, 28, 128)        16512     \n",
      " onvLayer)                                                       \n",
      "                                                                 \n",
      " pixel_conv_layer_7 (PixelC  (128, 28, 28, 128)        16512     \n",
      " onvLayer)                                                       \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (128, 28, 28, 1)          129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 532673 (2.03 MB)\n",
      "Trainable params: 532673 (2.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "493/493 - 1594s - loss: 0.1153 - val_loss: 0.0953 - 1594s/epoch - 3s/step\n",
      "Epoch 2/50\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=input_shape, batch_size=128)\n",
    "x = PixelConvLayer(\n",
    "    mask_type=\"A\", filters=128, kernel_size=7, activation=\"relu\", padding=\"same\"\n",
    ")(inputs)\n",
    "\n",
    "for _ in range(n_residual_blocks):\n",
    "    x = ResidualBlock(filters=128)(x)\n",
    "\n",
    "for _ in range(2):\n",
    "    x = PixelConvLayer(\n",
    "        mask_type=\"B\",\n",
    "        filters=128,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        activation=\"relu\",\n",
    "        padding=\"valid\",\n",
    "    )(x)\n",
    "\n",
    "out = keras.layers.Conv2D(\n",
    "    filters=1, kernel_size=1, strides=1, activation=\"sigmoid\", padding=\"valid\"\n",
    ")(x)\n",
    "\n",
    "pixel_cnn = keras.Model(inputs, out)\n",
    "adam = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "pixel_cnn.compile(optimizer=adam, loss=\"binary_crossentropy\")\n",
    "\n",
    "pixel_cnn.summary()\n",
    "pixel_cnn.fit(\n",
    "    x=data, y=data, batch_size=128, epochs=50, validation_split=0.1, verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23c9818-9427-4c62-9ab7-a34dd96f7cf8",
   "metadata": {},
   "source": [
    "### Display real images from MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be65233-d3ce-48b0-90a0-69d2bfbcc6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = np.concatenate((x, y), axis=0)\n",
    "real_images = real_images.astype(np.float32)\n",
    "\n",
    "# Select 10 random images from the dataset\n",
    "indices = np.random.choice(range(len(real_images)), 10, replace=False)\n",
    "sample_real_images = real_images[indices]\n",
    "\n",
    "# Display these images in a 2x5 grid\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(sample_real_images[i], cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Real Images from MNIST')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be63ad-1724-447b-b5f6-066e25228186",
   "metadata": {},
   "source": [
    "### Display generated images from MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7377e6cb-9eac-4762-898a-ad95a56d46da",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = pixel_cnn.predict(np.random.rand(10, 28, 28, 1))  # Example generation\n",
    "\n",
    "# Display these generated images in a 2x5 grid\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Generated Images from PixelCNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4740b-f030-4273-b0d9-03da28ec2ed8",
   "metadata": {},
   "source": [
    "### Performance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1828b3-0258-4d1d-9261-e51e4924f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming `real_images` is your batch of real images and `generated_images` is your batch of generated images\n",
    "# Ensure both arrays are of the same shape\n",
    "\n",
    "# Flatten the images for simplicity in calculation\n",
    "real_images_flat = real_images.reshape(real_images.shape[0], -1)\n",
    "generated_images_flat = generated_images.reshape(generated_images.shape[0], -1)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) and then take the square root for RMSE\n",
    "mse = mean_squared_error(real_images_flat, generated_images_flat)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(real_images_flat, generated_images_flat)\n",
    "\n",
    "# Assuming binary cross-entropy loss, calculate it manually or retrieve it if you have it logged during training\n",
    "# Here's a simplified manual calculation for binary cross-entropy loss\n",
    "epsilon = 1e-7  # to prevent log(0)\n",
    "bce_loss = -np.mean(\n",
    "    real_images_flat * np.log(generated_images_flat + epsilon) + \n",
    "    (1 - real_images_flat) * np.log(1 - generated_images_flat + epsilon)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c98ab8-9ffd-4048-9ac5-d67917417b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'Metric': ['BCE Loss', 'RMSE', 'MAE'],\n",
    "    'Value': [bce_loss, rmse, mae]\n",
    "}\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_dict)\n",
    "\n",
    "print(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
